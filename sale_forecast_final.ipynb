{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "indonesian-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "single-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_hdf(\"../input/sales_train.h5\")\n",
    "df_test = pd.read_hdf(\"../input/sales_test.h5\")\n",
    "\n",
    "# df = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "preceding-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = pd.read_csv('../input/stores_data.csv')\n",
    "df_train = pd.merge(df_train, stores, how='left', left_on='store', right_on='Store').drop('Store', axis=1)\n",
    "df_test = pd.merge(df_test, stores, how='left', left_on='store', right_on='Store').drop('Store', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "thousand-qualification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 285089 entries, 0 to 285088\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   id            285089 non-null  int32  \n",
      " 1   weekly_sales  285089 non-null  float32\n",
      " 2   store         285089 non-null  int8   \n",
      " 3   dept          285089 non-null  int8   \n",
      " 4   date          285089 non-null  object \n",
      " 5   is_holiday    285089 non-null  bool   \n",
      " 6   Type          285089 non-null  object \n",
      " 7   Size          285089 non-null  int64  \n",
      "dtypes: bool(1), float32(1), int32(1), int64(1), int8(2), object(2)\n",
      "memory usage: 11.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sporting-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_cat(x):\n",
    "    if x == 'A':\n",
    "        return 1\n",
    "    elif x == 'B':\n",
    "        return 2\n",
    "    return 3\n",
    "df_train['type_cat'] = df_train['Type'].map(type_cat)\n",
    "df_train['date_date'] = pd.to_datetime(df_train['date'], format='%d/%m/%Y')\n",
    "df_train['month'] = df_train['date_date'].dt.month\n",
    "df_train['week'] = df_train['date_date'].dt.week\n",
    "df_train['holidays'] = df_train['week'].isin(['47', '50', '51']).astype('int')\n",
    "df_train = df_train.sort_values(by='date_date')\n",
    "\n",
    "df_test['type_cat'] = df_test['Type'].map(type_cat)\n",
    "df_test['date_date'] = pd.to_datetime(df_test['date'], format='%d/%m/%Y')\n",
    "df_test['month'] = df_test['date_date'].dt.month\n",
    "df_test['week'] = df_test['date_date'].dt.week\n",
    "df_test['holidays'] = df_test['week'].isin(['47', '50', '51']).astype('int')\n",
    "\n",
    "df_stde = df_train.groupby(['store', 'dept']).agg(['mean', 'std', 'median'])['weekly_sales'].reset_index()\n",
    "df_train = pd.merge(df_train, df_stde, on=['store', 'dept'], how='left').fillna(-1)\n",
    "df_test = pd.merge(df_test, df_stde, on=['store', 'dept'], how='left').fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spectacular-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set feats to use in algorithm\n",
    "feats_num = df_train.select_dtypes(['number', 'boolean']).columns\n",
    "feats_drop = ['id', 'weekly_sales']\n",
    "\n",
    "def get_feat(feats_num, feats_drop, feats_add=[]):\n",
    "#     print(feats_drop)\n",
    "    feats = [feat for feat in feats_num if feat not in feats_drop]\n",
    "    return feats + feats_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "understood-discrimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost parameters\n",
    "params = {'max_depth': 5,\n",
    "            'colsample_bytree': 0.9,\n",
    "            'learning_rate': 0.2,\n",
    "            'subsample': 0.9,\n",
    "            'random_state': 21,\n",
    "            'n_estimators': 100,\n",
    "            }\n",
    "\n",
    "def validate_model(df_train, feats, params, eli=False):\n",
    "    X = df_train[feats].values\n",
    "    y = df_train['weekly_sales'].values\n",
    "    train_size = int(len(X) * 0.7)\n",
    "    X_train, X_test = X[0:train_size], X[train_size:len(X)]\n",
    "    y_train, y_test = y[0:train_size], y[train_size:len(X)] \n",
    "\n",
    "    model = XGBRegressor(**params)\n",
    "    y_train_log = np.log(y_train - (np.min(y_train) -1))\n",
    "    model.fit(X_train, y_train_log)\n",
    "    y_pred_log = model.predict(X_test)\n",
    "    y_pred = np.exp(y_pred_log) + (np.min(y_train) -1)\n",
    "    score = mean_absolute_error(y_test, y_pred)\n",
    "    print('MAE: {}'.format(score))\n",
    "\n",
    "    if eli:\n",
    "        model.fit(X, y)\n",
    "        display(eli5.show_weights(model, feature_names=feats))\n",
    "        \n",
    "def submit(df_train, df_test, feats, params):\n",
    "    \n",
    "    X = df_train[feats].values\n",
    "    y = df_train['weekly_sales'].values\n",
    "    X_test = df_test[feats].values\n",
    "    \n",
    "    model = XGBRegressor(**params)\n",
    "    y_log = np.log(y - (np.min(y) -1))\n",
    "    model.fit(X, y_log)\n",
    "    y_pred_log = model.predict(X_test)\n",
    "    y_pred = np.exp(y_pred_log) + (np.min(y) -1)\n",
    "    \n",
    "    df_test['weekly_sales'] = y_pred\n",
    "    df_test[ ['id', 'weekly_sales'] ].to_csv(\"../output/xgb_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bronze-camping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1731.110107421875\n"
     ]
    }
   ],
   "source": [
    "params = {'max_depth': 9,\n",
    "            'colsample_bytree': 0.9,\n",
    "            'learning_rate': 0.15,\n",
    "            'subsample': 0.9,\n",
    "            'random_state': 21,\n",
    "            'n_estimators':300,\n",
    "            }\n",
    "feats = get_feat(feats_num, feats_drop)\n",
    "validate_model(df_train, feats, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adopted-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = get_feat(feats_num, feats_drop)\n",
    "submit(df_train, df_test, feats, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-lyric",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
